## [AAAI 26] Duplex Rewards Optimization for Test-Time Composed Image Retrieval [![paper](https://img.shields.io/badge/Paper-87CEEB)](https://github.com/HaoliangZhou/TT-RLDR/blob/master/TT-RLDR_paper.pdf) <br> 
*Haoliang Zhou, Feifei Zhang, Changsheng Xu* <br> 

##

## Abstract <br>
Composed Image Retrieval (CIR) combines the reference image with text to retrieve the intended target image. Recently, zero-shot CIR has gained significant attention by eliminating the need for labeled triplets required in supervised CIR. However, it inevitably demands additional training corpus, storage, and computational resources, limiting its applicability in real-world scenarios. Inspired by advancements in Test-Time Adaptation (TTA), we propose a Test-Time CIR setting named TT-CIR, which aims to efficiently adapt models to unlabeled test samples while reducing resource consumption. Within the TT-CIR setting, we identify that naively introducing existing TTA methods (e.g., reward-based) into CIR faces two vital challenges: 1) Modification-restricted reward pool, which limits the exploration of semantically relevant candidate rewards; 2) Conservative knowledge feedback, which inhibits the adaptability of rewards to the current data distribution. To address these challenges, we propose a test-time reinforcement learning framework that integrates a Counterfactual-guided Multinomial Sampling (CMS) strategy and a Duplex Rewards Modeling (DRM) module. The CMS explores a candidate reward pool that is visually similar and semantically relevant to the given query, while the DRM generates stable and adaptive duplex rewards to guide model adaptation. Extensive experiments demonstrate the superiority and adaptability of our method over existing approaches.

<p align="center">
<img src="https://github.com/HaoliangZhou/TT-RLDR/blob/master/ttrldr.png" width=100% height=100% 
class="center">
</p>


## Setup and Environments
- Basic environments
```
*  Python=3.10
*  PyTorch=2.2.1
*  Nvidia Driver Version=560.35.03
*  CUDA Version=12.1
```

- Installation the package requirements
```
pip install -r environment.yml
```

- Installation the revelant packages and remove them to the `models/third_party` folder
```
# For open_clip
pip install open_clip_torch

# For LAVIS
git clone https://github.com/salesforce/LAVIS.git
cd LAVIS
pip install -e .
```

---
## Data Preparation
Overall structure of this directory should be as follows. 
```bash
data
   ├── coco
   ├── CIRR
   └── fashion-iq
```

### COCO
```bash
 coco
   ├── annotations/instances_val2017.json ## annotations for COCO validation images.
   ├── prepare_data.py ## code to generate query data.
   ├── coco_eval.csv ## this will be generated by running prepare_data.py
   ├── val2017 ## directory containing COCO validation images.
   └── val2017_masked ## running prepare_data.py will produce the directory.
```
Download both instances_val2017.json and val2017. 
Run the command to below to produce directory of val2017_masked.
```bash
python prepare_data.py
```

### CIRR

```
cirr
  ├── captions
        └──cap.rc2.val.json
  ├── dev
  └── image_splits
        └──split.rc2.val.json
```
Download the images following instruction on [CIRR](https://github.com/Cuberick-Orion/CIRR).

### Fashion-IQ

```
fashion-iq
    ├── json
        ├── cap.dress.val.json
        ├── cap.shirt.val.json
        └── cap.toptee.val.json
    ├── image_splits
        ├── split.dress.val.json
        ├── split.shirt.val.json
        └── split.toptee.val.json
    └── images ## images under this directory.
```
Json files are available in https://github.com/XiaoxiaoGuo/fashion-iq. 
Images are downloaded from https://github.com/postBG/CosMo.pytorch. 

## Test-Time Adaption and Evaluation
1. Modify the file paths of the dataset `DATA_DIR` in `cfgs/coir/reawrd.yaml` to your path.
2. We provide config files for our method on CIRR as example. Simply run the following Python file with the corresponding config file.
    ```
    python test_time.py \
        --cfg cfgs/coir/reward.yaml \  # TTA methods: [source, reward, tent, etc.]
        CORRUPTION.DATASET cirr \   # datasets: [cirr, fashioniq, coco]
        CORRUPTION.DATASET_FIQTYPE= 'dress'\  # this for fashioniq type, ['dress', 'toptee', 'shirt'] 
        OPTIM.MIXTURE_FACTOR_TEXT 0.8 \
        REWARD.TEACHER_TEXT_FACTOR 0.8 \
        OPTIM.FUSION_TYPE lerp \
        OPTIM.METHOD AdamW \
        OPTIM.LR 0.0005 \
        OPTIM.STEPS 1 \
        REWARD.CLIP_SCORE_WEIGHT 2.5 \
        REWARD.SAMPLE_K 8 \
        REWARD.SAMPLING_TYPE "temperature" \
        RNG_SEED 1 \
        REWARD.BASEINE_SCORE RLOO \
        MODEL.USE_CLIP True \
        MODEL.ARCH ViT-B-16 \
        REWARD.REWARD_ARCH ViT-L-14 \
        REWARD.USE_SELF_REWARD True \
        SAVE_DIR "./output/log" 
    ```
3. The corresponding training log will be written in the `output/log` folder.
4. You can also run the following script:
    ```
    sh run_script.sh
    ```
